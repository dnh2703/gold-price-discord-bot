---
description: 
globs: 
alwaysApply: true
---
```
Custom Cursor Rule System (Tof's Prompt)
‚îÇ
‚îú‚îÄ‚îÄ Core Goal: Make the Cursor AI assistant smarter, more consistent, and context-aware for coding tasks.
‚îÇ
‚îú‚îÄ‚îÄ Key Capabilities (The "Toolkit"):
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üß† Memory (M):
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Remembers context, decisions, code snippets across sessions.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Stores info in .cursor/memory/.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Trigger: "Remember this...", "Recall...", "Check memory..."
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìú Rule Engine (Œõ):
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Learns and applies custom coding standards/preferences.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Stores rules as .mdc files in .cursor/rules/.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Trigger: "Create a rule for...", "Apply rules...", "Suggest a rule..."
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üêû Error Tracking (Œû):
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Logs recurring errors to avoid repetition.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Stores logs in .cursor/memory/errors.md.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Trigger: "Track this error...", "Why does this keep happening?"
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìã Task Planning (T):
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Breaks down complex tasks into manageable steps.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Supports Agile/TDD approaches.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Stores plans in .cursor/tasks/.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Trigger: "Plan the steps for...", "Break down this task...", "Generate TDD spec..."
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ ‚öôÔ∏è Structured Reasoning (Œ©, Œ¶, D‚ç∫, etc.):
‚îÇ       ‚îî‚îÄ‚îÄ Internal AI Guidance (Symbols used by the author).
‚îÇ       ‚îî‚îÄ‚îÄ User doesn't need to use or know these symbols.
‚îÇ       ‚îî‚îÄ‚îÄ Aims for focused, efficient processing by the AI.
‚îÇ
‚îú‚îÄ‚îÄ Author's Philosophy (Why the Symbols?):
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Semantic Compression (Shorthand for AI).
‚îÇ   ‚îú‚îÄ‚îÄ Symbolic Abstraction (Guiding AI thought).
‚îÇ   ‚îú‚îÄ‚îÄ Reduce Ambiguity / Increase Focus.
‚îÇ   ‚îî‚îÄ‚îÄ Note: Effectiveness debated vs. plain English.
‚îÇ
‚îú‚îÄ‚îÄ How YOU Use It:
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Setup: Paste the entire prompt into Cursor Settings -> Rules (Optional: wrap in cognition ... ).
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Interaction: Use PLAIN ENGLISH commands.
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Focus On: Using KEYWORDS to trigger specific capabilities (see above triggers).
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Review: Check the generated files in the .cursor/ directory (memory, rules, tasks).
‚îÇ
‚îî‚îÄ‚îÄ Use Case: Implementing New Features:
‚îÇ
‚îú‚îÄ‚îÄ General Strategy: Be specific, use keywords, reference files (@path/to/file), break down tasks, iterate.
‚îÇ
‚îú‚îÄ‚îÄ Example Approaches:
‚îÇ   ‚îú‚îÄ‚îÄ Simple: "Implement feature X, follow rules."
‚îÇ   ‚îú‚îÄ‚îÄ Planning: "Plan feature Y using Agile steps." -> "Implement step 1..."
‚îÇ   ‚îú‚îÄ‚îÄ TDD: "Using TDD, implement feature Z. First, generate tests..." -> "Write code to pass tests..."
‚îÇ   ‚îú‚îÄ‚îÄ Memory: "Implement feature A. Remember decision B (check memory)..."
‚îÇ   ‚îî‚îÄ‚îÄ Combined: Mix keywords (Plan, TDD, Remember, Rule) for complex features.
```
---
**The 3Ac Framework**

This framework seems to be the author's philosophy for designing advanced LLM prompts, focusing on making the AI more efficient, structured, and adaptable.

1. **Semantic Compression:**
    - **Concept:** Packing the most *meaning* (semantics) into the fewest possible characters or tokens. It's about density of information, not just shortening words.
    - **Analogy:** Think of mathematical notation (‚à´ f(x) dx is much shorter and more precise than "calculate the definite integral of the function f with respect to x over a given interval") or chemical formulas (H‚ÇÇO vs. "a molecule made of two hydrogen atoms and one oxygen atom").
    - **Why for LLMs:**
        - **Token Efficiency:** LLMs have context limits (a maximum number of tokens they can process). Compression allows fitting more instructions or background info within that limit.
        - **Reduced Ambiguity (Potentially):** Well-defined symbols *might* be less open to interpretation than natural language sentences, guiding the AI more precisely. (Though LLMs can sometimes misinterpret symbols too).
        - **Signaling Structure:** Using a distinct symbolic language might signal to the LLM that this is a core instruction set, separate from the user's conversational input.
    - **In the Prompt:** The dense lines with Greek letters and mathematical-like operators are the prime examples. The author believes these convey complex instructions concisely.
2. **Symbolic Abstraction:**
    - **Concept:** Using symbols (Œ©, Œõ, M, etc.) to represent abstract *concepts*, *processes*, or functional *modules* within the AI's desired cognitive architecture.
    - **Analogy:** In a flowchart, symbols represent 'start', 'process', 'decision', etc. In programming, keywords like class or function represent abstract structures. Here, symbols represent conceptual parts of the AI's "mind."
    - **Why for LLMs:**
        - **Modularity:** Breaks down the complex task of "being a helpful AI assistant" into distinct, manageable functional units (memory, reasoning, rules, error checking).
        - **Structure:** Provides a schema or mental map for the LLM. It helps organize how different instructions relate to each other.
        - **Targeted Activation:** The hope is the LLM can identify which "module" (symbol) is most relevant to the user's current request and activate the associated instructions.
    - **In the Prompt:** Assigning M for memory, Œõ for rules, T for tasks, etc., creates these abstract functional blocks.
3. **Dynamic Cognitive Regulation:**
    - **Concept:** The system's ability to *adjust its own internal processes* and priorities based on the situation (e.g., task complexity, detected errors, user feedback). It's about self-management, adaptation, and optimization *during* operation.
    - **Analogy:** A car's cruise control adjusting the throttle to maintain speed on hills, or a thermostat adjusting heating/cooling based on room temperature.
    - **Why for LLMs:**
        - **Adaptability:** Allows the AI to use simpler processes for easy tasks and more complex ones (like detailed planning or deep rule checking) for difficult tasks, saving effort.
        - **Prioritization:** Focuses the AI's "attention" or computational resources where they are most needed.
        - **Self-Improvement:** Enables mechanisms like learning from errors (Œû tracking leading to Œõ rule generation) or adjusting weights (ùö´*).
    - **In the Prompt:** The ùö´* section explicitly defines weight adjustments based on task_complexity. The Œ£_hooks define specific trigger-action behaviors. The entire error-tracking (Œû) and rule-generation (Œõ) loop is a form of dynamic self-regulation.

**Symbol Representations (Interpretation)**

Here's a breakdown of the main symbols based on their descriptions in the prompt:

- **Œ© (Omega): Core Reasoning & Cognition**
    - Represents the central "thinking" part of the AI. It likely handles understanding the user's intent, initial processing, generating hypotheses, and coordinating other modules.
    - Œ©* = max(‚àáŒ£Œ©) suggests optimizing this core reasoning process.
    - Œ©_H (Hierarchical decomposition) points to breaking down problems.
    - Œ©‚Çú (Self-validation) involves evaluating confidence in its own hypotheses.
    - Modes (deductive, analogical...) indicate different reasoning styles it might adopt.
- **M (Memory): Persistent Storage & Recall**
    - Represents the file-based memory system (.cursor/memory/).
    - Focuses on long-term knowledge storage and contextual recall.
    - M.sync suggests saving relevant insights during reviews.
- **T (Tasks): Structured Task Management**
    - Manages complex tasks, breaking them down into steps (.cursor/tasks/).
    - Includes planning, decomposition, progress tracking, and potentially Agile/TDD workflows (TDD.spec_engine).
- **Œõ (Lambda): Rules & Learning Engine**
    - Handles the creation, storage (.cursor/rules/), application, and refinement of rules (heuristics, standards, patterns).
    - Includes rule generation (self-improvement), naming conventions, conflict resolution, and triggering based on context (e.g., errors, patterns).
    - Œõ.autonomy suggests proactive rule drafting.
- **Œû (Xi): Diagnostics, Error Tracking & Refinement**
    - Focuses on identifying problems, tracking recurring errors (.cursor/memory/errors.md), and suggesting corrections or simplifications.
    - Œû.self-correction links errors back to rules (Œõ) for improvement.
    - Œû.cleanup_phase suggests proactive code health checks.
- **Œ¶ (Phi): Hypothesis Abstraction & Innovation Engine**
    - Seems related to generating novel ideas, identifying emergent patterns, or abstracting design motifs (Œ¶.snapshot) that go beyond existing explicit rules (Œõ). It's more exploratory.
    - Œ¶_H (Abstraction-driven enhancement) emphasizes this exploratory problem-solving aspect.
- **D‚ç∫ (Delta Alpha variant): Contradiction Resolution**
    - Specifically designed to identify and handle conflicts, ambiguities, or contradictions in information or instructions.
- **Œ® (Psi): Cognitive Trace & Metacognition**
    - Acts like a "flight recorder" for the AI's thinking process.
    - Logs which modules were active, the reasoning path, errors encountered, rules invoked (.cursor/memory/trace_...md).
    - Enables reflection (Œ®.sprint_reflection) and potentially dialogue about its own process (Œ®.dialog_enabled).
- **Œ£ (Sigma): Summation / Integration / System Hooks**
    - Often used mathematically for summation. Here, it seems to represent integration or overarching systems.
    - Œ£(œÑ_complex) defines the Task system.
    - Œ£Œ©(...) might represent factors influencing reasoning.
    - Œ£_hooks explicitly defines the event-driven system linking different modules (e.g., on_error_detected: [Œû.track, Œõ.suggest]).
- **ùö´ (Delta variant - uppercase): Dynamic Weighting & Prioritization**
    - Represents the dynamic regulation mechanism itself.
    - ùö´* defines how the weights/importance of different modules (Œ©, D, Œ£, Œ¶, Œû) should change based on task_complexity.
- **Other Symbols (Œ≤, Œ≥, Œ¥, œÑ, Œª, Œ∏, Œ∂, œá, etc.):**
    - These likely represent specific parameters, inputs, conditions, weights, or intermediate states within the more complex symbolic equations (like the first Œ©* line). Their exact meaning is deeply embedded in the author's intended mathematical/logical structure but less crucial for understanding the overall function of the main modules (Œ©, M, T, Œõ, Œû, Œ¶, D‚ç∫, Œ®, ùö´). œÑ often seems related to the current task/input, and Œª might relate to memory or rules.

In essence, the author designed a blueprint for an AI assistant with specialized "mental tools" (symbols/modules), aiming for efficient (compressed), structured (abstracted), and adaptive (dynamically regulated) behavior, all specified through this unique symbolic language. You interact with the *results* of this system using plain English, triggering these underlying mechanisms.